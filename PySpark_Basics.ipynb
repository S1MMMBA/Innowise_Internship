{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-moses",
   "metadata": {},
   "source": [
    "import libraries(I provide all libs that I need when make this tasks, if you need some external import them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "induced-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max, avg, min\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import when\n",
    "from distutils.version import LooseVersion\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-photographer",
   "metadata": {},
   "source": [
    "create local SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stock-partnership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Ivan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FirstSparkApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dc5b47ac90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"FirstSparkApp\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-blame",
   "metadata": {},
   "source": [
    "read csv with inferschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "computational-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"ds_salaries.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-dominant",
   "metadata": {},
   "source": [
    "read csv one more time with the same code and you will see that it almostly don't take time, because info already in SparkSession and it will not read nothing\n",
    "from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aging-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-tomorrow",
   "metadata": {},
   "source": [
    "write schema of scv on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "least-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-brother",
   "metadata": {},
   "source": [
    "create schema of this scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "progressive-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"id\",IntegerType(),True), \\\n",
    "    StructField(\"work_year\",IntegerType(),True), \\\n",
    "    StructField(\"experience_level\",StringType(),True), \\\n",
    "    StructField(\"employment_type\", StringType(), True), \\\n",
    "    StructField(\"job_title\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True), \\\n",
    "    StructField(\"salary_currency\", StringType(), True), \\\n",
    "    StructField(\"salary_in_usd\", IntegerType(), True), \\\n",
    "    StructField(\"employee_residence\", StringType(), True), \\\n",
    "    StructField(\"remote_ratio\", IntegerType(), True), \\\n",
    "    StructField(\"company_location\", StringType(), True), \\\n",
    "    StructField(\"company_size\", StringType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-sauce",
   "metadata": {},
   "source": [
    "restart kernel without cleaning output and after restarting you need to initialize SparkSession, after initialize start execute only cells from cell with schema=\n",
    "=StructType.... \n",
    "To restart kernel click Kernel, Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-hospital",
   "metadata": {},
   "source": [
    "read ds_salaries with predefined schema and compare results from this cell and cell with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "literary-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"FirstSparkApp\").getOrCreate()\n",
    "df2 = spark.read.schema(schema).option(\"header\",True).csv(\"ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-joint",
   "metadata": {},
   "source": [
    "this happens because read operation is lazy(transformation), but if you use inferschema it start to be action that will create Spark Job, because Spark need to loop throw all file to check datatypes for all columns and this can harm to your code(if we compare to parquet, it will also go to check data types, but parquet provide meta information, so Spark will not go throw all file, he will just read meta information, but csv don't provide such meta information). Also header make Spark to create one more Spark Job to check first line\n",
    "to define name of columns and remember to skeep it when reading. Actual reading start when you will use first action. More about Spark Jobs you will see in next topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-assurance",
   "metadata": {},
   "source": [
    "write schema of scv on screen one more time and compare with previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "solid-infection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-water",
   "metadata": {},
   "source": [
    "now continue to work with one of the dataframes that you create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-belgium",
   "metadata": {},
   "source": [
    "print data in dataframe using df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "legendary-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "| id|work_year|experience_level|employment_type|           job_title|  salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|  0|     2020|              MI|             FT|      Data Scientist|   70000|            EUR|        79833|                DE|           0|              DE|           L|\n",
      "|  1|     2020|              SE|             FT|Machine Learning ...|  260000|            USD|       260000|                JP|           0|              JP|           S|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer|   85000|            GBP|       109024|                GB|          50|              GB|           M|\n",
      "|  3|     2020|              MI|             FT|Product Data Analyst|   20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|  4|     2020|              SE|             FT|Machine Learning ...|  150000|            USD|       150000|                US|          50|              US|           L|\n",
      "|  5|     2020|              EN|             FT|        Data Analyst|   72000|            USD|        72000|                US|         100|              US|           L|\n",
      "|  6|     2020|              SE|             FT| Lead Data Scientist|  190000|            USD|       190000|                US|         100|              US|           S|\n",
      "|  7|     2020|              MI|             FT|      Data Scientist|11000000|            HUF|        35735|                HU|          50|              HU|           L|\n",
      "|  8|     2020|              MI|             FT|Business Data Ana...|  135000|            USD|       135000|                US|         100|              US|           L|\n",
      "|  9|     2020|              SE|             FT|  Lead Data Engineer|  125000|            USD|       125000|                NZ|          50|              NZ|           S|\n",
      "| 10|     2020|              EN|             FT|      Data Scientist|   45000|            EUR|        51321|                FR|           0|              FR|           S|\n",
      "| 11|     2020|              MI|             FT|      Data Scientist| 3000000|            INR|        40481|                IN|           0|              IN|           L|\n",
      "| 12|     2020|              EN|             FT|      Data Scientist|   35000|            EUR|        39916|                FR|           0|              FR|           M|\n",
      "| 13|     2020|              MI|             FT|   Lead Data Analyst|   87000|            USD|        87000|                US|         100|              US|           L|\n",
      "| 14|     2020|              MI|             FT|        Data Analyst|   85000|            USD|        85000|                US|         100|              US|           L|\n",
      "| 15|     2020|              MI|             FT|        Data Analyst|    8000|            USD|         8000|                PK|          50|              PK|           L|\n",
      "| 16|     2020|              EN|             FT|       Data Engineer| 4450000|            JPY|        41689|                JP|         100|              JP|           S|\n",
      "| 17|     2020|              SE|             FT|   Big Data Engineer|  100000|            EUR|       114047|                PL|         100|              GB|           S|\n",
      "| 18|     2020|              EN|             FT|Data Science Cons...|  423000|            INR|         5707|                IN|          50|              IN|           M|\n",
      "| 19|     2020|              MI|             FT|  Lead Data Engineer|   56000|            USD|        56000|                PT|         100|              US|           M|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-medium",
   "metadata": {},
   "source": [
    "print data in dataframe using display(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "connected-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  work_year experience_level employment_type  \\\n",
       "0      0       2020               MI              FT   \n",
       "1      1       2020               SE              FT   \n",
       "2      2       2020               SE              FT   \n",
       "3      3       2020               MI              FT   \n",
       "4      4       2020               SE              FT   \n",
       "..   ...        ...              ...             ...   \n",
       "602  602       2022               SE              FT   \n",
       "603  603       2022               SE              FT   \n",
       "604  604       2022               SE              FT   \n",
       "605  605       2022               SE              FT   \n",
       "606  606       2022               MI              FT   \n",
       "\n",
       "                      job_title  salary salary_currency  salary_in_usd  \\\n",
       "0                Data Scientist   70000             EUR          79833   \n",
       "1    Machine Learning Scientist  260000             USD         260000   \n",
       "2             Big Data Engineer   85000             GBP         109024   \n",
       "3          Product Data Analyst   20000             USD          20000   \n",
       "4     Machine Learning Engineer  150000             USD         150000   \n",
       "..                          ...     ...             ...            ...   \n",
       "602               Data Engineer  154000             USD         154000   \n",
       "603               Data Engineer  126000             USD         126000   \n",
       "604                Data Analyst  129000             USD         129000   \n",
       "605                Data Analyst  150000             USD         150000   \n",
       "606                AI Scientist  200000             USD         200000   \n",
       "\n",
       "    employee_residence  remote_ratio company_location company_size  \n",
       "0                   DE             0               DE            L  \n",
       "1                   JP             0               JP            S  \n",
       "2                   GB            50               GB            M  \n",
       "3                   HN             0               HN            S  \n",
       "4                   US            50               US            L  \n",
       "..                 ...           ...              ...          ...  \n",
       "602                 US           100               US            M  \n",
       "603                 US           100               US            M  \n",
       "604                 US             0               US            M  \n",
       "605                 US           100               US            M  \n",
       "606                 IN           100               US            L  \n",
       "\n",
       "[607 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-gazette",
   "metadata": {},
   "source": [
    "create df_job_title that consists from all job_titles without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "friendly-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_title = df2.select(col(\"job_title\")).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-architecture",
   "metadata": {},
   "source": [
    "print all rows from df_job_titles without truncating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "asian-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|job_title                               |\n",
      "+----------------------------------------+\n",
      "|3D Computer Vision Researcher           |\n",
      "|Lead Data Engineer                      |\n",
      "|Head of Machine Learning                |\n",
      "|Data Specialist                         |\n",
      "|Data Analytics Lead                     |\n",
      "|Machine Learning Scientist              |\n",
      "|Lead Data Analyst                       |\n",
      "|Data Engineering Manager                |\n",
      "|Staff Data Scientist                    |\n",
      "|ETL Developer                           |\n",
      "|Director of Data Engineering            |\n",
      "|Product Data Analyst                    |\n",
      "|Principal Data Scientist                |\n",
      "|AI Scientist                            |\n",
      "|Director of Data Science                |\n",
      "|Machine Learning Engineer               |\n",
      "|Lead Data Scientist                     |\n",
      "|Machine Learning Infrastructure Engineer|\n",
      "|Data Science Engineer                   |\n",
      "|Machine Learning Manager                |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_title.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-pharmacy",
   "metadata": {},
   "source": [
    "create  df_analytic that will consists from max, avg, min USD salaries for all job_titles using groupBy. name of fields is avg_salary, min_salary, max_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "naval-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df2.groupBy(\"job_title\") \\\n",
    "                    .agg(max(\"salary_in_usd\").alias(\"max_salary\"), \\\n",
    "                         avg(\"salary_in_usd\").alias(\"avg_salary\"), \\\n",
    "                         min(\"salary_in_usd\").alias(\"min_salary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-pledge",
   "metadata": {},
   "source": [
    "print all rows from df_analytic without trancating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bacterial-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------+------------------+----------+\n",
      "|job_title                               |max_salary|avg_salary        |min_salary|\n",
      "+----------------------------------------+----------+------------------+----------+\n",
      "|3D Computer Vision Researcher           |5409      |5409.0            |5409      |\n",
      "|Lead Data Engineer                      |276000    |139724.5          |56000     |\n",
      "|Head of Machine Learning                |79039     |79039.0           |79039     |\n",
      "|Data Specialist                         |165000    |165000.0          |165000    |\n",
      "|Data Analytics Lead                     |405000    |405000.0          |405000    |\n",
      "|Machine Learning Scientist              |260000    |158412.5          |12000     |\n",
      "|Lead Data Analyst                       |170000    |92203.0           |19609     |\n",
      "|Data Engineering Manager                |174000    |123227.2          |59303     |\n",
      "|Staff Data Scientist                    |105000    |105000.0          |105000    |\n",
      "|ETL Developer                           |54957     |54957.0           |54957     |\n",
      "|Director of Data Engineering            |200000    |156738.0          |113476    |\n",
      "|Product Data Analyst                    |20000     |13036.0           |6072      |\n",
      "|Principal Data Scientist                |416000    |215242.42857142858|148261    |\n",
      "|AI Scientist                            |200000    |66135.57142857143 |12000     |\n",
      "|Director of Data Science                |325000    |195074.0          |130026    |\n",
      "|Machine Learning Engineer               |250000    |104880.14634146342|20000     |\n",
      "|Lead Data Scientist                     |190000    |115190.0          |40570     |\n",
      "|Machine Learning Infrastructure Engineer|195000    |101145.0          |50180     |\n",
      "|Data Science Engineer                   |127221    |75803.33333333333 |40189     |\n",
      "|Machine Learning Manager                |117104    |117104.0          |117104    |\n",
      "+----------------------------------------+----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analytic.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-color",
   "metadata": {},
   "source": [
    "now you need to add in df_analytic column row_id, that will show order of all job_titles depending on avg salary. they should be descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "nearby-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.orderBy(col(\"avg_salary\").desc())\n",
    "df_analytic = df_analytic.withColumn(\"row_id\",row_number().over(windowSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-catalog",
   "metadata": {},
   "source": [
    "print all data from df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "confirmed-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics Lead</td>\n",
       "      <td>405000</td>\n",
       "      <td>405000.000000</td>\n",
       "      <td>405000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>600000</td>\n",
       "      <td>328333.333333</td>\n",
       "      <td>185000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>450000</td>\n",
       "      <td>275000.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>416000</td>\n",
       "      <td>215242.428571</td>\n",
       "      <td>148261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director of Data Science</td>\n",
       "      <td>325000</td>\n",
       "      <td>195074.000000</td>\n",
       "      <td>130026</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>266400</td>\n",
       "      <td>177873.909091</td>\n",
       "      <td>90700</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>380000</td>\n",
       "      <td>175655.000000</td>\n",
       "      <td>54238</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Analytics Engineer</td>\n",
       "      <td>205300</td>\n",
       "      <td>175000.000000</td>\n",
       "      <td>135000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000.000000</td>\n",
       "      <td>165000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Head of Data</td>\n",
       "      <td>235000</td>\n",
       "      <td>160162.600000</td>\n",
       "      <td>32974</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>158412.500000</td>\n",
       "      <td>12000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>241000</td>\n",
       "      <td>158328.500000</td>\n",
       "      <td>54094</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Director of Data Engineering</td>\n",
       "      <td>200000</td>\n",
       "      <td>156738.000000</td>\n",
       "      <td>113476</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>224000</td>\n",
       "      <td>146718.750000</td>\n",
       "      <td>85000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Applied Machine Learning Scientist</td>\n",
       "      <td>423000</td>\n",
       "      <td>142068.750000</td>\n",
       "      <td>31875</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>276000</td>\n",
       "      <td>139724.500000</td>\n",
       "      <td>56000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>150260</td>\n",
       "      <td>127134.285714</td>\n",
       "      <td>105400</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cloud Data Engineer</td>\n",
       "      <td>160000</td>\n",
       "      <td>124647.000000</td>\n",
       "      <td>89294</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Engineering Manager</td>\n",
       "      <td>174000</td>\n",
       "      <td>123227.200000</td>\n",
       "      <td>59303</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Principal Data Analyst</td>\n",
       "      <td>170000</td>\n",
       "      <td>122500.000000</td>\n",
       "      <td>75000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>270000</td>\n",
       "      <td>117504.000000</td>\n",
       "      <td>15966</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Machine Learning Manager</td>\n",
       "      <td>117104</td>\n",
       "      <td>117104.000000</td>\n",
       "      <td>117104</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>190000</td>\n",
       "      <td>115190.000000</td>\n",
       "      <td>40570</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>324000</td>\n",
       "      <td>112725.000000</td>\n",
       "      <td>4000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>450000</td>\n",
       "      <td>109019.500000</td>\n",
       "      <td>42000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>412000</td>\n",
       "      <td>108187.832168</td>\n",
       "      <td>2859</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Computer Vision Software Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>105248.666667</td>\n",
       "      <td>70000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>105000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>250000</td>\n",
       "      <td>104880.146341</td>\n",
       "      <td>20000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Machine Learning Infrastructure Engineer</td>\n",
       "      <td>195000</td>\n",
       "      <td>101145.000000</td>\n",
       "      <td>50180</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Big Data Architect</td>\n",
       "      <td>99703</td>\n",
       "      <td>99703.000000</td>\n",
       "      <td>99703</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>200000</td>\n",
       "      <td>92893.061856</td>\n",
       "      <td>6072</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>170000</td>\n",
       "      <td>92203.000000</td>\n",
       "      <td>19609</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>88654</td>\n",
       "      <td>88654.000000</td>\n",
       "      <td>88654</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lead Machine Learning Engineer</td>\n",
       "      <td>87932</td>\n",
       "      <td>87932.000000</td>\n",
       "      <td>87932</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Machine Learning Developer</td>\n",
       "      <td>100000</td>\n",
       "      <td>85860.666667</td>\n",
       "      <td>78791</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Head of Machine Learning</td>\n",
       "      <td>79039</td>\n",
       "      <td>79039.000000</td>\n",
       "      <td>79039</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>135000</td>\n",
       "      <td>76691.200000</td>\n",
       "      <td>18442</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>127221</td>\n",
       "      <td>75803.333333</td>\n",
       "      <td>40189</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BI Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>74755.166667</td>\n",
       "      <td>9272</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>103000</td>\n",
       "      <td>69420.714286</td>\n",
       "      <td>5707</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>66135.571429</td>\n",
       "      <td>12000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>110000</td>\n",
       "      <td>64799.250000</td>\n",
       "      <td>20000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Finance Data Analyst</td>\n",
       "      <td>61896</td>\n",
       "      <td>61896.000000</td>\n",
       "      <td>61896</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>54957</td>\n",
       "      <td>54957.000000</td>\n",
       "      <td>54957</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>114047</td>\n",
       "      <td>51974.000000</td>\n",
       "      <td>5882</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>125000</td>\n",
       "      <td>44419.333333</td>\n",
       "      <td>10000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>37236</td>\n",
       "      <td>37236.000000</td>\n",
       "      <td>37236</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>13036.000000</td>\n",
       "      <td>6072</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3D Computer Vision Researcher</td>\n",
       "      <td>5409</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   job_title  max_salary     avg_salary  \\\n",
       "0                        Data Analytics Lead      405000  405000.000000   \n",
       "1                    Principal Data Engineer      600000  328333.333333   \n",
       "2                     Financial Data Analyst      450000  275000.000000   \n",
       "3                   Principal Data Scientist      416000  215242.428571   \n",
       "4                   Director of Data Science      325000  195074.000000   \n",
       "5                             Data Architect      266400  177873.909091   \n",
       "6                     Applied Data Scientist      380000  175655.000000   \n",
       "7                         Analytics Engineer      205300  175000.000000   \n",
       "8                            Data Specialist      165000  165000.000000   \n",
       "9                               Head of Data      235000  160162.600000   \n",
       "10                Machine Learning Scientist      260000  158412.500000   \n",
       "11                      Data Science Manager      241000  158328.500000   \n",
       "12              Director of Data Engineering      200000  156738.000000   \n",
       "13                      Head of Data Science      224000  146718.750000   \n",
       "14        Applied Machine Learning Scientist      423000  142068.750000   \n",
       "15                        Lead Data Engineer      276000  139724.500000   \n",
       "16                    Data Analytics Manager      150260  127134.285714   \n",
       "17                       Cloud Data Engineer      160000  124647.000000   \n",
       "18                  Data Engineering Manager      174000  123227.200000   \n",
       "19                    Principal Data Analyst      170000  122500.000000   \n",
       "20                               ML Engineer      270000  117504.000000   \n",
       "21                  Machine Learning Manager      117104  117104.000000   \n",
       "22                       Lead Data Scientist      190000  115190.000000   \n",
       "23                             Data Engineer      324000  112725.000000   \n",
       "24                        Research Scientist      450000  109019.500000   \n",
       "25                            Data Scientist      412000  108187.832168   \n",
       "26         Computer Vision Software Engineer      150000  105248.666667   \n",
       "27                      Staff Data Scientist      105000  105000.000000   \n",
       "28                 Machine Learning Engineer      250000  104880.146341   \n",
       "29  Machine Learning Infrastructure Engineer      195000  101145.000000   \n",
       "30                        Big Data Architect       99703   99703.000000   \n",
       "31                              Data Analyst      200000   92893.061856   \n",
       "32                         Lead Data Analyst      170000   92203.000000   \n",
       "33                    Marketing Data Analyst       88654   88654.000000   \n",
       "34            Lead Machine Learning Engineer       87932   87932.000000   \n",
       "35                Machine Learning Developer      100000   85860.666667   \n",
       "36                  Head of Machine Learning       79039   79039.000000   \n",
       "37                     Business Data Analyst      135000   76691.200000   \n",
       "38                     Data Science Engineer      127221   75803.333333   \n",
       "39                           BI Data Analyst      150000   74755.166667   \n",
       "40                   Data Science Consultant      103000   69420.714286   \n",
       "41                              AI Scientist      200000   66135.571429   \n",
       "42                   Data Analytics Engineer      110000   64799.250000   \n",
       "43                      Finance Data Analyst       61896   61896.000000   \n",
       "44                             ETL Developer       54957   54957.000000   \n",
       "45                         Big Data Engineer      114047   51974.000000   \n",
       "46                  Computer Vision Engineer      125000   44419.333333   \n",
       "47                              NLP Engineer       37236   37236.000000   \n",
       "48                      Product Data Analyst       20000   13036.000000   \n",
       "49             3D Computer Vision Researcher        5409    5409.000000   \n",
       "\n",
       "    min_salary  row_id  \n",
       "0       405000       1  \n",
       "1       185000       2  \n",
       "2       100000       3  \n",
       "3       148261       4  \n",
       "4       130026       5  \n",
       "5        90700       6  \n",
       "6        54238       7  \n",
       "7       135000       8  \n",
       "8       165000       9  \n",
       "9        32974      10  \n",
       "10       12000      11  \n",
       "11       54094      12  \n",
       "12      113476      13  \n",
       "13       85000      14  \n",
       "14       31875      15  \n",
       "15       56000      16  \n",
       "16      105400      17  \n",
       "17       89294      18  \n",
       "18       59303      19  \n",
       "19       75000      20  \n",
       "20       15966      21  \n",
       "21      117104      22  \n",
       "22       40570      23  \n",
       "23        4000      24  \n",
       "24       42000      25  \n",
       "25        2859      26  \n",
       "26       70000      27  \n",
       "27      105000      28  \n",
       "28       20000      29  \n",
       "29       50180      30  \n",
       "30       99703      31  \n",
       "31        6072      32  \n",
       "32       19609      33  \n",
       "33       88654      34  \n",
       "34       87932      35  \n",
       "35       78791      36  \n",
       "36       79039      37  \n",
       "37       18442      38  \n",
       "38       40189      39  \n",
       "39        9272      40  \n",
       "40        5707      41  \n",
       "41       12000      42  \n",
       "42       20000      43  \n",
       "43       61896      44  \n",
       "44       54957      45  \n",
       "45        5882      46  \n",
       "46       10000      47  \n",
       "47       37236      48  \n",
       "48        6072      49  \n",
       "49        5409      50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_analytic.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-quarter",
   "metadata": {},
   "source": [
    "it isn't beautifull, so we need to put now row_id on first place in df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ranging-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df_analytic.selectExpr(\"row_id\", \"max_salary\", \"min_salary\", \"avg_salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-amsterdam",
   "metadata": {},
   "source": [
    "print df_analytic now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "classical-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>405000</td>\n",
       "      <td>405000</td>\n",
       "      <td>405000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>600000</td>\n",
       "      <td>185000</td>\n",
       "      <td>328333.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>450000</td>\n",
       "      <td>100000</td>\n",
       "      <td>275000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>416000</td>\n",
       "      <td>148261</td>\n",
       "      <td>215242.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>325000</td>\n",
       "      <td>130026</td>\n",
       "      <td>195074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>266400</td>\n",
       "      <td>90700</td>\n",
       "      <td>177873.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>380000</td>\n",
       "      <td>54238</td>\n",
       "      <td>175655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>205300</td>\n",
       "      <td>135000</td>\n",
       "      <td>175000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>235000</td>\n",
       "      <td>32974</td>\n",
       "      <td>160162.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>260000</td>\n",
       "      <td>12000</td>\n",
       "      <td>158412.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>241000</td>\n",
       "      <td>54094</td>\n",
       "      <td>158328.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>200000</td>\n",
       "      <td>113476</td>\n",
       "      <td>156738.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>224000</td>\n",
       "      <td>85000</td>\n",
       "      <td>146718.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>423000</td>\n",
       "      <td>31875</td>\n",
       "      <td>142068.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>276000</td>\n",
       "      <td>56000</td>\n",
       "      <td>139724.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>150260</td>\n",
       "      <td>105400</td>\n",
       "      <td>127134.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>160000</td>\n",
       "      <td>89294</td>\n",
       "      <td>124647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>174000</td>\n",
       "      <td>59303</td>\n",
       "      <td>123227.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>170000</td>\n",
       "      <td>75000</td>\n",
       "      <td>122500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>270000</td>\n",
       "      <td>15966</td>\n",
       "      <td>117504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>117104</td>\n",
       "      <td>117104</td>\n",
       "      <td>117104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>190000</td>\n",
       "      <td>40570</td>\n",
       "      <td>115190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>324000</td>\n",
       "      <td>4000</td>\n",
       "      <td>112725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>450000</td>\n",
       "      <td>42000</td>\n",
       "      <td>109019.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>412000</td>\n",
       "      <td>2859</td>\n",
       "      <td>108187.832168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>150000</td>\n",
       "      <td>70000</td>\n",
       "      <td>105248.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>250000</td>\n",
       "      <td>20000</td>\n",
       "      <td>104880.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>195000</td>\n",
       "      <td>50180</td>\n",
       "      <td>101145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>99703</td>\n",
       "      <td>99703</td>\n",
       "      <td>99703.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>200000</td>\n",
       "      <td>6072</td>\n",
       "      <td>92893.061856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>170000</td>\n",
       "      <td>19609</td>\n",
       "      <td>92203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>88654</td>\n",
       "      <td>88654</td>\n",
       "      <td>88654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>87932</td>\n",
       "      <td>87932</td>\n",
       "      <td>87932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>100000</td>\n",
       "      <td>78791</td>\n",
       "      <td>85860.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>79039</td>\n",
       "      <td>79039</td>\n",
       "      <td>79039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>135000</td>\n",
       "      <td>18442</td>\n",
       "      <td>76691.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>127221</td>\n",
       "      <td>40189</td>\n",
       "      <td>75803.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>150000</td>\n",
       "      <td>9272</td>\n",
       "      <td>74755.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>103000</td>\n",
       "      <td>5707</td>\n",
       "      <td>69420.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>200000</td>\n",
       "      <td>12000</td>\n",
       "      <td>66135.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>110000</td>\n",
       "      <td>20000</td>\n",
       "      <td>64799.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>61896</td>\n",
       "      <td>61896</td>\n",
       "      <td>61896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>54957</td>\n",
       "      <td>54957</td>\n",
       "      <td>54957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>114047</td>\n",
       "      <td>5882</td>\n",
       "      <td>51974.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>125000</td>\n",
       "      <td>10000</td>\n",
       "      <td>44419.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>37236</td>\n",
       "      <td>37236</td>\n",
       "      <td>37236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>20000</td>\n",
       "      <td>6072</td>\n",
       "      <td>13036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>5409</td>\n",
       "      <td>5409</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  max_salary  min_salary     avg_salary\n",
       "0        1      405000      405000  405000.000000\n",
       "1        2      600000      185000  328333.333333\n",
       "2        3      450000      100000  275000.000000\n",
       "3        4      416000      148261  215242.428571\n",
       "4        5      325000      130026  195074.000000\n",
       "5        6      266400       90700  177873.909091\n",
       "6        7      380000       54238  175655.000000\n",
       "7        8      205300      135000  175000.000000\n",
       "8        9      165000      165000  165000.000000\n",
       "9       10      235000       32974  160162.600000\n",
       "10      11      260000       12000  158412.500000\n",
       "11      12      241000       54094  158328.500000\n",
       "12      13      200000      113476  156738.000000\n",
       "13      14      224000       85000  146718.750000\n",
       "14      15      423000       31875  142068.750000\n",
       "15      16      276000       56000  139724.500000\n",
       "16      17      150260      105400  127134.285714\n",
       "17      18      160000       89294  124647.000000\n",
       "18      19      174000       59303  123227.200000\n",
       "19      20      170000       75000  122500.000000\n",
       "20      21      270000       15966  117504.000000\n",
       "21      22      117104      117104  117104.000000\n",
       "22      23      190000       40570  115190.000000\n",
       "23      24      324000        4000  112725.000000\n",
       "24      25      450000       42000  109019.500000\n",
       "25      26      412000        2859  108187.832168\n",
       "26      27      150000       70000  105248.666667\n",
       "27      28      105000      105000  105000.000000\n",
       "28      29      250000       20000  104880.146341\n",
       "29      30      195000       50180  101145.000000\n",
       "30      31       99703       99703   99703.000000\n",
       "31      32      200000        6072   92893.061856\n",
       "32      33      170000       19609   92203.000000\n",
       "33      34       88654       88654   88654.000000\n",
       "34      35       87932       87932   87932.000000\n",
       "35      36      100000       78791   85860.666667\n",
       "36      37       79039       79039   79039.000000\n",
       "37      38      135000       18442   76691.200000\n",
       "38      39      127221       40189   75803.333333\n",
       "39      40      150000        9272   74755.166667\n",
       "40      41      103000        5707   69420.714286\n",
       "41      42      200000       12000   66135.571429\n",
       "42      43      110000       20000   64799.250000\n",
       "43      44       61896       61896   61896.000000\n",
       "44      45       54957       54957   54957.000000\n",
       "45      46      114047        5882   51974.000000\n",
       "46      47      125000       10000   44419.333333\n",
       "47      48       37236       37236   37236.000000\n",
       "48      49       20000        6072   13036.000000\n",
       "49      50        5409        5409    5409.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_analytic.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-queensland",
   "metadata": {},
   "source": [
    "here you need to create df_exp_lvl with the biggest usd_salary(biggest_salary) for each experience_level(you need to save all fields like in entire dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dental-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"experience_level\")\n",
    "df_exp_lvl = df2.withColumn(\"biggest_salary\",max(\"salary_in_usd\").over(windowSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-hierarchy",
   "metadata": {},
   "source": [
    "print here df_exp_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "standing-toilet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>biggest_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>72000</td>\n",
       "      <td>USD</td>\n",
       "      <td>72000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>45000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>51321</td>\n",
       "      <td>FR</td>\n",
       "      <td>0</td>\n",
       "      <td>FR</td>\n",
       "      <td>S</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>35000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>39916</td>\n",
       "      <td>FR</td>\n",
       "      <td>0</td>\n",
       "      <td>FR</td>\n",
       "      <td>M</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4450000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>41689</td>\n",
       "      <td>JP</td>\n",
       "      <td>100</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>423000</td>\n",
       "      <td>INR</td>\n",
       "      <td>5707</td>\n",
       "      <td>IN</td>\n",
       "      <td>50</td>\n",
       "      <td>IN</td>\n",
       "      <td>M</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>597</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>170000</td>\n",
       "      <td>USD</td>\n",
       "      <td>170000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>602</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>603</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>604</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>605</td>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  work_year experience_level employment_type                job_title  \\\n",
       "0      5       2020               EN              FT             Data Analyst   \n",
       "1     10       2020               EN              FT           Data Scientist   \n",
       "2     12       2020               EN              FT           Data Scientist   \n",
       "3     16       2020               EN              FT            Data Engineer   \n",
       "4     18       2020               EN              FT  Data Science Consultant   \n",
       "..   ...        ...              ...             ...                      ...   \n",
       "602  597       2022               SE              FT             Data Analyst   \n",
       "603  602       2022               SE              FT            Data Engineer   \n",
       "604  603       2022               SE              FT            Data Engineer   \n",
       "605  604       2022               SE              FT             Data Analyst   \n",
       "606  605       2022               SE              FT             Data Analyst   \n",
       "\n",
       "      salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0      72000             USD          72000                 US           100   \n",
       "1      45000             EUR          51321                 FR             0   \n",
       "2      35000             EUR          39916                 FR             0   \n",
       "3    4450000             JPY          41689                 JP           100   \n",
       "4     423000             INR           5707                 IN            50   \n",
       "..       ...             ...            ...                ...           ...   \n",
       "602   170000             USD         170000                 US           100   \n",
       "603   154000             USD         154000                 US           100   \n",
       "604   126000             USD         126000                 US           100   \n",
       "605   129000             USD         129000                 US             0   \n",
       "606   150000             USD         150000                 US           100   \n",
       "\n",
       "    company_location company_size  biggest_salary  \n",
       "0                 US            L          250000  \n",
       "1                 FR            S          250000  \n",
       "2                 FR            M          250000  \n",
       "3                 JP            S          250000  \n",
       "4                 IN            M          250000  \n",
       "..               ...          ...             ...  \n",
       "602               US            M          412000  \n",
       "603               US            M          412000  \n",
       "604               US            M          412000  \n",
       "605               US            M          412000  \n",
       "606               US            M          412000  \n",
       "\n",
       "[607 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_exp_lvl.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-mortgage",
   "metadata": {},
   "source": [
    "create df_best that consists from rows where salary of guy same as biggest salary for other people in his exp_lvl and choose only columns: id, experience_level, biggest_salary, employee_residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b9af241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_exp_lvl.select(\"id\", \"experience_level\", \"biggest_salary\", \"employee_residence\").where(df_exp_lvl[\"salary_in_usd\"] == df_exp_lvl[\"biggest_salary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-librarian",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "smart-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>biggest_salary</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>EN</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>EX</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>SE</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id experience_level  biggest_salary employee_residence\n",
       "0   37               EN          250000                 US\n",
       "1  252               EX          600000                 US\n",
       "2   33               MI          450000                 US\n",
       "3   97               MI          450000                 US\n",
       "4   63               SE          412000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_best.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-brass",
   "metadata": {},
   "source": [
    "drop duplicates if exist by experience_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "immune-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_best.dropDuplicates([\"experience_level\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-credit",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "specified-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>biggest_salary</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>EN</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>EX</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>MI</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>SE</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id experience_level  biggest_salary employee_residence\n",
       "0   37               EN          250000                 US\n",
       "1  252               EX          600000                 US\n",
       "2   33               MI          450000                 US\n",
       "3   63               SE          412000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_best.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-plant",
   "metadata": {},
   "source": [
    "create df_new_best from df_best without id, and make the next: when exp_level = MI we want middle, when SE we want senior, else Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "infinite-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_best = df_best.drop(\"id\").withColumn(\"experience_level\", when(df_best.experience_level == \"MI\",\"middle\")\n",
    "                                                                .when(df_best.experience_level == \"SE\",\"senior\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-fairy",
   "metadata": {},
   "source": [
    "print df_new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "endless-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>biggest_salary</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senior</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_level  biggest_salary employee_residence\n",
       "0             None          250000                 US\n",
       "1             None          600000                 US\n",
       "2           middle          450000                 US\n",
       "3           senior          412000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_new_best.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-status",
   "metadata": {},
   "source": [
    "write df_new_best like 1.csv and load then it to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "baking-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_best.toPandas().to_csv('1.csv')\n",
    "df_final = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-shooting",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "expired-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>biggest_salary</th>\n",
       "      <th>employee_residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>250000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>600000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>middle</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0 experience_level  biggest_salary employee_residence\n",
       "0    0             None          250000                 US\n",
       "1    1             None          600000                 US\n",
       "2    2           middle          450000                 US\n",
       "3    3           senior          412000                 US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-progress",
   "metadata": {},
   "source": [
    "filter df_final to delete experience_level where it Null, then join this table by biggest_salary(salary_in_usd) and employee_residence with entire df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "small-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.where(col(\"experience_level\").isNotNull()).join(df2,(df_final.biggest_salary == df2.salary_in_usd) & (df_final.employee_residence == df2.employee_residence),\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-twins",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "generic-block",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>biggest_salary</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>id</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>middle</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>450000</td>\n",
       "      <td>USD</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>senior</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "      <td>63</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>412000</td>\n",
       "      <td>USD</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>middle</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "      <td>97</td>\n",
       "      <td>2021</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>450000</td>\n",
       "      <td>USD</td>\n",
       "      <td>450000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0 experience_level  biggest_salary employee_residence  id  work_year  \\\n",
       "0    2           middle          450000                 US  33       2020   \n",
       "1    3           senior          412000                 US  63       2020   \n",
       "2    2           middle          450000                 US  97       2021   \n",
       "\n",
       "  experience_level employment_type               job_title  salary  \\\n",
       "0               MI              FT      Research Scientist  450000   \n",
       "1               SE              FT          Data Scientist  412000   \n",
       "2               MI              FT  Financial Data Analyst  450000   \n",
       "\n",
       "  salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0             USD         450000                 US             0   \n",
       "1             USD         412000                 US           100   \n",
       "2             USD         450000                 US           100   \n",
       "\n",
       "  company_location company_size  \n",
       "0               US            M  \n",
       "1               US            L  \n",
       "2               US            L  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-moore",
   "metadata": {},
   "source": [
    "last task is to save in variable and then print this variable of the biggest salary_in_usd from df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "individual-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(_c0=2, experience_level='middle', biggest_salary=450000, employee_residence='US', id=33, work_year=2020, experience_level='MI', employment_type='FT', job_title='Research Scientist', salary=450000, salary_currency='USD', salary_in_usd=450000, employee_residence='US', remote_ratio=0, company_location='US', company_size='M')\n",
      "Row(_c0=2, experience_level='middle', biggest_salary=450000, employee_residence='US', id=97, work_year=2021, experience_level='MI', employment_type='FT', job_title='Financial Data Analyst', salary=450000, salary_currency='USD', salary_in_usd=450000, employee_residence='US', remote_ratio=100, company_location='US', company_size='L')\n"
     ]
    }
   ],
   "source": [
    "max_salary = df_final.agg(max('salary_in_usd').alias('max_salary_in_usd')).collect()[0]['max_salary_in_usd']\n",
    "highest_salary_rows = df_final.filter(df_final['salary_in_usd'] == max_salary).collect()\n",
    "for row in highest_salary_rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-procedure",
   "metadata": {},
   "source": [
    "It is the end of PySpark basics. In other lessons you will learn optimizations technics and how to make distributed system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
